{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset 88%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch:  1 cost:  3.15005518762\n",
      "Epoch:  2 cost:  1.15658033897\n",
      "Epoch:  3 cost:  0.907257671736\n",
      "Epoch:  4 cost:  0.783496842764\n",
      "Epoch:  5 cost:  0.706427406642\n",
      "Epoch:  6 cost:  0.652018086856\n",
      "Epoch:  7 cost:  0.611638684056\n",
      "Epoch:  8 cost:  0.579997879009\n",
      "Epoch:  9 cost:  0.553607919812\n",
      "Epoch:  10 cost:  0.53198624321\n",
      "Epoch:  11 cost:  0.513541707735\n",
      "Epoch:  12 cost:  0.497852323814\n",
      "Epoch:  13 cost:  0.483820096322\n",
      "Epoch:  14 cost:  0.471402888853\n",
      "Epoch:  15 cost:  0.460808066617\n",
      "Accuracy:  0.8871\n",
      "Label:  [4]\n",
      "Prediction:  [4]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+IGkCD+QFOEHkvp/syAWzr9uUnMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d615eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# MNIST Dataset 가져오기\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# shape = 28 * 28\n",
    "nb_classes = 10\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# hypothesis - sosftmax\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "# cost\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "# minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# measure\n",
    "predicted = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(predicted, tf.argmax(Y, 1)) # 에측값이 참이면 True, 아니면 False\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# batch로 작업\n",
    "training_epochs = 15 # 전체 데이터 셋을 모두 한번씩 학습시키는 것을 1 epoch이라고 한다\n",
    "batch_size = 100 # 한번에 읽어들일 사이즈\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost= 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, train], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c/total_batch\n",
    "        print('Epoch: ', epoch+1, 'cost: ', avg_cost)\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "    # image\n",
    "    r = random.randint(0, mnist.test.num_examples -1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r: r+1]}))\n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset - 88%, tf.nn.softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch:  1 cost:  2.78742144303\n",
      "Epoch:  2 cost:  1.12016672362\n",
      "Epoch:  3 cost:  0.889920785833\n",
      "Epoch:  4 cost:  0.77735334101\n",
      "Epoch:  5 cost:  0.706883215552\n",
      "Epoch:  6 cost:  0.657534817999\n",
      "Epoch:  7 cost:  0.619544817182\n",
      "Epoch:  8 cost:  0.588623138341\n",
      "Epoch:  9 cost:  0.563394873576\n",
      "Epoch:  10 cost:  0.541895863414\n",
      "Epoch:  11 cost:  0.524321266616\n",
      "Epoch:  12 cost:  0.508230610043\n",
      "Epoch:  13 cost:  0.494108646119\n",
      "Epoch:  14 cost:  0.48165662519\n",
      "Epoch:  15 cost:  0.470508746518\n",
      "Accuracy:  0.8877\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1f5f4aa33ede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# MNIST Dataset 가져오기\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# shape = 28 * 28\n",
    "nb_classes = 10\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.int32, [None, nb_classes])\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# hypothesis - sosftmax\n",
    "logits = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "# cost\n",
    "# Y_one_hot = tf.one_hot(Y, nb_classes)\n",
    "# Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "# minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# measure\n",
    "predicted = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(predicted, tf.argmax(Y, 1)) # 에측값이 참이면 True, 아니면 False\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# batch로 작업\n",
    "training_epochs = 15 # 전체 데이터 셋을 모두 한번씩 학습시키는 것을 1 epoch이라고 한다\n",
    "batch_size = 100 # 한번에 읽어들일 사이즈\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost= 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, train], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c/total_batch\n",
    "        print('Epoch: ', epoch+1, 'cost: ', avg_cost)\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "    image\n",
    "    r = random.randint(0, mnist.test.num_examples -1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r: r+1]}))\n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
